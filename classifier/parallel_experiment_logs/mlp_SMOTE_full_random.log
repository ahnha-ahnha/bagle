=== ì‹¤í—˜ ì‹œì‘: mlp_SMOTE_full_random ===
GPU: 6
ì‹œì‘ ì‹œê°„: Tue Jul 15 00:35:45 UTC 2025

wandb: Currently logged in as: ahnha (ahnha_ahnha) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: creating run
wandb: Tracking run with wandb version 0.21.0
wandb: Run data is saved locally in /home/user14/bagle/classifier/wandb/run-20250715_003552-2hpwal6f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run adni_ct_mlp_SMOTE_full_random_fold_1
wandb: â­ï¸ View project at https://wandb.ai/ahnha_ahnha/adni_ct_mlp
wandb: ğŸš€ View run at https://wandb.ai/ahnha_ahnha/adni_ct_mlp/runs/2hpwal6f
Auto-generated run_name: adni_ct_mlp_SMOTE_full_random
Loading data from: /home/user14/bagle/data/ADNI_CT/real.pt
Data loaded successfully:
  Samples: 1644
  Features shape: torch.Size([1644, 160, 1])
  Labels shape: torch.Size([1644])
  Unique labels: tensor([0, 1, 2, 3, 4])
  Fold values: tensor([0, 1, 2, 3, 4])
Number of classes: 5
Using existing fold information for K-fold cross validation
Fold 0: 1309 train samples, 335 test samples
Fold 1: 1316 train samples, 328 test samples
Fold 2: 1331 train samples, 313 test samples
Fold 3: 1308 train samples, 336 test samples
Fold 4: 1312 train samples, 332 test samples
save directory:  ./logs/20250715_003550


=============================== Fold 1 ===============================
Loaded synthetic data from SMOTE_full_fold0.pt: 1386 samples
SMOTE synthetic data - using class-based adjacency matrices
Using SMOTE_full augmentation: 1386 additional samples
Adding 1386 augmented samples to training set
Generating adjacency matrices for 1386 synthetic samples using random method
Assigning random adjacency matrices for 1386 synthetic samples (Option-R)
Random adjacency assignment:
  Class 0: 154 synthetic samples
  Class 1: 386 synthetic samples
  Class 2: 155 synthetic samples
  Class 3: 290 synthetic samples
  Class 4: 401 synthetic samples
Final training set size: 2695 samples
Traceback (most recent call last):
  File "/home/user14/bagle/classifier/main.py", line 647, in <module>
    main()
  File "/home/user14/bagle/classifier/main.py", line 535, in main
    val_acc_list, val_sens_list, val_prec_list = trainer.train()
  File "/home/user14/bagle/classifier/utils/train.py", line 367, in train
    output = self.network.forward(feature)
  File "/home/user14/bagle/classifier/models/mlp.py", line 28, in forward
    x = self.pred(x)
  File "/opt/conda/envs/bagle_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/envs/bagle_env/lib/python3.10/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/opt/conda/envs/bagle_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/envs/bagle_env/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:6 and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)
[1;34mwandb[0m: 
[1;34mwandb[0m: ğŸš€ View run [33madni_ct_mlp_SMOTE_full_random_fold_1[0m at: [34mhttps://wandb.ai/ahnha_ahnha/adni_ct_mlp/runs/2hpwal6f[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250715_003552-2hpwal6f/logs[0m

ì¢…ë£Œ ì‹œê°„: Tue Jul 15 00:35:59 UTC 2025
ì¢…ë£Œ ì½”ë“œ: 1
âœ— ì‹¤í—˜ ì‹¤íŒ¨: mlp_SMOTE_full_random (ì½”ë“œ: 1)
